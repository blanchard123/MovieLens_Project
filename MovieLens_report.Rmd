---
title: "MovieLens Capstone Project:  \n  HarvardX PH125.9x Data Science Capstone"
author: "Adam J. E. Blanchard"
date: "May 2, 2021"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    highlight: tango

---
\pagebreak

# Overview  

Based roughly on the Netflix challenge (https://www.netflixprize.com), this project aimed to develop a machine learning algorithm to predict movie ratings using the publicly available MovieLens dataset (https://movielens.org) collected by GroupLens Research. The dataset contains 10 million user ratings of over 10,000 different movies. The aim of the project was to develop a predictive algorithm that would result in the lowest root mean squared error (RMSE) in a partitioned validation dataset. In particular, this report details the installation, cleaning, and exploration of the MovieLens data, as well as the development and evaluation of several predictive models.  

## Introduction  

Recommendation systems utilize user generated ratings of items in order to provide specific recommendations for other items. Many companies use recommendation systems in their pursuits. Typically, companies that sell products or services to a large volume of customers and also allow customers to rate these items or services are then able to amass extremely large datasets of user ratings. These datasets can then be used to develop algorithms used to make predictions of specific user ratings for given items. The use of these algorithms allows the companies to make specific item recommendations to specific users that the users is likely to rate highly or prefer. Recommendation systems are used in a variety of areas including movies, books, articles, and social media by many well-known companies including Amazon, Netflix, Spotify and Twitter.  

Recommendation systems are a common machine learning application. For instance, Netflix uses an advanced machine learning algorithm to provide media recommendations. The Netflix prize was an open competition announced in 2006 to the data science community. The goal was to find the best filtering algorithm to predict how much a user is going to enjoy a show or movie based on prior movie ratings; the company aimed to find an algorithm that would improve their current system by at least 10%. The $1 million prize was awarded in 2009 to the team “BellKor’s Pragmatic Chaos” using an advance ensemble of machine learning techniques (https://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf).  

## Aim of the Project  

This project aimed to accomplish a similar feat to the Netflix challenge. Specifically, the aim was to develop an efficient movie recommendation algorithm using machine learning techniques on the MovieLens dataset. The utility of the algorithm is based on the resultant loss function.  

## Specific Requirements of the Project  

The 10M version of the MovieLens data will be used in order to develop a predictive model. The dataset will be separated into a training set (edx) and a test set (final hold-out validation set). The final predictive model will be evaluated based on its performance in the final hold-out validation set.  

The loss function used to evaluate the predictive algorithm is the root mean square error (RMSE), which is a common metric of distance between the predicted and observed values. Values of RMSE will be used to evaluate the accuracy of the predictive models during the training phase and used to determine the overall accuracy of the final model using the validation set. As a measure of distance between predicted and observed values, lower values of RMSE indicate more accurate predictions. The specific RMSE formula used in this project is provided here:  
$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$  

## Dataset  

MovieLens is an online service that provides movie recommendations to its users, as well as conducts online experiments related to recommendation system and interfaces. For this project the 10M MovieLens dataset will be used (https://grouplens.org/datasets/movielens/10m/). This dataset contains over 10 million movies ratings for 10,681 unique movies by 71,567 users of the online service. Users were selected at random to be included in the dataset provided that they had rated at least 20 movies. 

Information from MovieLens regarding the dataset reveals the following features:  

* No user information is provided in the dataset; all users have been anonymized and assigned a unique UserID code.  
* Ratings are made on a 5-star scale system, which includes half-star increments (i.e., scale extends from 0.5 to 5.0 with increments of 0.5).  
* The timestamp of each rating is included and represents the number of seconds since midnight Universal Time (UTC) of January 1, 1970.  
* MovieID numbers are provided directly by MovieLens, while movie titles are entered manually in the format found on IMBD which includes the year of release in parentheses following the title.  
* Genre information is stored in a pipe-separated list representing the relevant combination of the following 19 genre options: action, adventure, animation, children’s, comedy, crime, documentary, drama, fantasy, film-noir, horror, musical, mystery, romance, sci-fi, thriller, war, western.  
\

# Data Wrangling  

The code to download and create the dataset was provided by the HarvardX PH125.9x Data Science Capstone course (see the complete code for the project in the supplemental code file).

Code was also provided by the course to partition the MovieLens dataset into two subsets: the edx dataset (90%) and the final hold-out validation dataset (10%).  

1. The edx dataset will be used for exploratory data analysis, testing different models, and developing the predictive algorithm.  
2. The validation dataset will only be used to test the accuracy of the final predictive model, and the overall accuracy of the model will be based on the resulting RMSE from this dataset.  

In order to ensure that we do not include users and/or movies in the validation data that do not appear in the edx data, we need to remove those entries using the code porovided by the course.  

```{r install data, echo = FALSE, warning = FALSE, message = FALSE}

##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

########################################################################
# Completed creating edx set, validation set (final hold-out test set)
########################################################################
```

```{r install libraries, echo = FALSE, warning = FALSE, message = FALSE}

if(!require(caretEnsemble)) install.packages("caretEnsemble", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(gam)) install.packages("gam", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(ggthemes)) install.packages("ggthemes", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(markdown)) install.packages("markdown", repos = "http://cran.us.r-project.org")
if(!require(matrixStats)) install.packages("matrixStats", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(Rborist)) install.packages("Rborist", repos = "http://cran.us.r-project.org")
if(!require(scales)) install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(stringr)) install.packages("stringr", repos = "http://cran.us.r-project.org")

library(caretEnsemble)
library(gam)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(knitr)
library(kableExtra)
library(lubridate)
library(markdown)
library(matrixStats)
library(randomForest)
library(Rborist)
library(scales)
library(stringr)
library(dplyr)
```

## Data Inspection  

After wrangling the data using the provided code, it can be seen that the edx and validation datasets both contain the aforementioned six variables (i.e., userID, movieID, rating, timestamp, title, and genres). Notably, the outcome of interest that we are interested in predicting is the movie rating variable. The edx dataset contains 9,000,055 ratings, while the validation dataset contains 999,999 ratings. This is consistent with our partitioning of the data (i.e., 90% to edx and 10% to validation). 
\

```{r basic identification of edx variables, echo = FALSE}
str(edx, strict.width="cut")
```
\
\

```{r basic identification of validation variables, echo = FALSE}
str(validation, strict.width="cut")
```
\

Looking at Table 1, it is apparent that each row represents a single rating from a single user for a single movie. As the validation dataset will only be used to test the final model, we examine the edx dataset in more detail. Looking at the data, several important features are immediately apparent:  

* The userID and movieID variables are stored as interger and numeric variables, respectively; these variabels shoud be treated as factors or grouping variabels in much of the analyses. 
* As the timestamp represents the seconds since midnight UTC January 1, 1970, and is stored as an interger variabels in the daatset; it will likely require some transformation or careful processing in order be used in any models.  
* As the movie titles are entered with the year of release in parentheses following the title as a character string, the year will need to be extracted in order to be used in any models.  
* As the genre is stored in a pipe-separated list representing the relevant combination of 19 genre options, there are several manners in which this variable could be treated; for instance, the overall combinations could be considered separate categories or the individual genre options could be considered features of each applicable movie.  
\

```{r table of edx variables, echo = FALSE}
as_tibble(edx) %>% slice(1:10) %>% 
  kable(caption = "Examination of the edx Data Structure", align = "c") %>%
  kable_styling(font_size = 10, position = "center", latex_options = "scale_down")
```
\

## Data Transformations  

Based on the current state of the variables, several tranformations of the data were undertaken. First, the timestamp variable was transformed from a the seconds since midnight UTC January 1, 1970, into a date variable. Converting this variable to represent the date of the rating will aid in the exmaination and interpretation of the effectof timing of the rating. Second, the date of the movie release was extracted from the title variable. In ther current form, with the date incldued in the title variable as a string of characters, the variable does not facilitate the exmaination of any effects of the age of the movie. As a result, the dates were extracted into a seperate variable hat represetns the year the movie was first released. Finally, the difference between the yearof the rating and the year of the movie release were calcuated based on the above two new variables. Thus, this variabels represents the number of years between the movie release and user rating of the movie. The code to complete tese transformations is presented below. After running this code, the data was checked for invalid and missing dates. 

In addition, the dataset could be converted from its current format in which a given row represents a single rating from a single user for a single movie. The dataset could be presented as a large matrix with users represented in the rows and movies represented in the columns. However, this dataset would be quite sprase, containing many missing values, as each user has not rated every single movie (i.e., 69,878 users have rated 10,677 movies). Moreover, due to the size of the edx dataset, reformatting the dataframe into this format would be relatively time consuming and require considerable memory. As such, the dataset was not converted into this matrix format. 
\

``` {r date and time transformations}
# transform timestamp to date of rating 
edx_dates <- edx %>% mutate(date_rated = as_datetime(timestamp))

# extracting the release date of each movie
edx_dates <- edx_dates %>% mutate(date_released = str_extract(edx$title, "\\((\\d{4})\\)"))
edx_dates <- edx_dates %>% mutate(date_released = str_extract(edx_dates$date_released, "(\\d{4})"))
edx_dates <- edx_dates %>% mutate(year_released = as.numeric(date_released))

# calculating the difference between release date and rating date 
edx_dates <- edx_dates %>% mutate(year_rated = year(date_rated)) %>%
  mutate(relative_rating_age = year_rated - as.numeric(year_released))

save(edx_dates, file = "edx_dates.RData")
```
\

# Exploratory Data Analysis  

The dataset contains a number of variables that could be used to predict ratings:  

* Movie effects: movies may have an impact on ratings  
* User effects: users may have an impact on ratings  
* Time (movie) effects: date of the movie release (i.e., year of release) may impact ratings  
* Time (rating) effects: date of the ratings (i.e., date the rating was made) may impact ratings
* Time (relative) effects: relative age of ratings (i.e., years between release and rating) may impact ratings  
* Genre effects: movie genres may have an impact on the ratings  

Table 2 presents the number of unique users and unique movies in the edx dataset. These values are slightly lower than the total number of unique users and movies in the edx dataset described above, which is consistent with the data partitioning into the edx and valdiation datasets.

```{r number of users and movies, echo = FALSE}
# number of different users and movies
edx %>% summarize(n_users = n_distinct(userId),
                 n_movies = n_distinct(movieId)) %>% 
  kable(col.names = c("Users", "Movies"), align = "c", 
        caption = "Distinct Users and Movies") %>%
    kable_styling(font_size = 10)
```

As seen in Table 3 and Figure 1, users tend to rate movies rather favorably. The minimum rating is 0.5 and the maximum is 5.0. Generally, whole-star ratings are more common than half-star ratings. The most common rating is 4.0 and the next most common 3.0, while ratings of 0.5 and 1.5 are relatively rare. The mean rating is 3.512, the median is 4.000, and the standard deviation is 1.060.

```{r table of ratings distribution, echo = FALSE}
# table of number of each rating in descending order 
edx %>% group_by(rating) %>% 
  summarize(number = n()) %>% 
  arrange(desc(number)) %>%
  kable(align = "c", caption = "Frequency of Most Common Ratings") %>%
  kable_styling(font_size = 10)
```
\

``` {r frequency distribution of ratings, echo = FALSE}
# plot of frequency of ratings
edx %>%
  ggplot(aes(rating)) +
  geom_bar(color = "Black", fill = "#00abff") +
  scale_y_continuous(labels = comma, breaks = pretty_breaks(n = 10)) +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Rating") +
  ylab("Frequency of Ratings") +
  theme_light() +
  ggtitle("Figure 1: Frequency Distribution of Ratings") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))
```
\

## Movie Effects  

Figure 2 presents the frequency at which each movie was rated. The graph shows ratings in log scale for ease of presentation. Based on this histogram, we can see that some movies are rated much more frequently than others, with some movies receiving only a single rating and other receiving over 30,000 ratings. In general, the majority of movies have received between 10 and 1000 ratings. Notably, 125 movies have only been rated a single time. This variability is exemplified in Tables 4 and 5, which present the most and least rated movies based on overall frequency of ratings. The variability in the number of ratings per movie may have an important impact in the development of our predictive model, as the estimates of the average movie rating will be based on substantially different numbers of ratings. The averages based on low numbers of ratings provide poorer estimates of the true means compared to those based on a large number of ratings.  

``` {r frequency of movie ratings, echo = FALSE}
# plot of frequency of movie ratings
edx %>%
  group_by(movieId) %>%
  summarize(number = n()) %>% 
  ggplot(aes(number)) +
  geom_histogram(bins = 50, color = "black", fill = "#00abff") +
  scale_x_log10(labels = comma) +
  scale_y_continuous(labels = comma, breaks = pretty_breaks(n = 10)) +
  xlab("Frequency of Ratings (log scale)") +
  ylab("Frequency of Movies") +
  theme_light() +
  ggtitle("Figure 2: Frequency of Movie Ratings (log scale)") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))
```
\

``` {r most rated movies, echo = FALSE, message = FALSE}
# movies with the greatest number of ratings
edx %>% group_by(movieId, title) %>% 
  summarise(number = n()) %>%
  arrange(desc(number)) %>%
  head(10) %>%
  kable(caption = "Most Rated Movies") %>%
  kable_styling(font_size = 10)
```
\

``` {r least rated movies, echo = FALSE, message = FALSE}
# movies with the least number of ratings
edx %>% group_by(movieId, title) %>% 
  summarise(number = n()) %>%
  arrange(number) %>%
  head(10) %>%
  kable(caption = "Least Rated Movies") %>%
  kable_styling(font_size = 10)
```
\

As well, Figure 3 presents the average movie rating (for movies that have been rated at least 100 times). Most movies have an average rating between 3.0 and 4.0; however there is considerable varition in the average movie rating. That is, from the graph, it is evident that movies differ substantially in their ratings. Some movies tend to receive much lower ratings compared to others. Thus, a movie effect may be useful in the predictive models.  

``` {r frequency of average movie ratings, echo = FALSE}
# plot of frequency of average movie rating
edx %>%
  group_by(movieId) %>%
  filter(n()>=100) %>%
  summarize(b_i = mean(rating)) %>% 
  ggplot(aes(b_i)) +
  geom_histogram(bins = 50, color = "Black", fill = "#00abff") +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  scale_y_continuous(labels = comma, breaks = pretty_breaks(n = 10)) +
  xlab("Average Rating") +
  ylab("Frequency of Movies") +
  theme_light() +
  ggtitle("Figure 3: Frequency of Average Movie Rating") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))
```
\

## User Effects  

Now looking at the effect of users on the movie ratings, Figure 4 presents the frequency at which each user provided ratings. The graph shows ratings in log scale for ease of presentation. Based on this histogram, we see the same pattern for users that is present for movies: large variability in the number of ratings per user. In general, the majority of users have provided between 30 and 500 ratings. Notably, four users have provided less than 14 ratings and 116 users have provided less than 16 ratings, whereas five users have provided more than 4000 ratings. This variability is is particularily noticeable in Tables 6 and 7 which present the users with the most and least ratings given, respectively.  

As is the case with the ratings per movie, the variability in the number of ratings per user may have an important impact in the development of our predictive model. The confidence in each of the average user effect will vary considerably due to the substantially different numbers of ratings per user, with some estimates being based on relatively low numbers of ratings. Due to the large variability in the number of ratings per movie and per user, the predictive models will likely benefit from the inclusion of regularization. Regularization involves applying a weight to the main effect terms (e.g., the movie and user effects) in order to control for differences in the number of ratings used to calculate the user and movie averages. In particular, averages based on low numbers of ratings are penalized due to the relative inaccuracy of these estimates, while the weight or penalty term has little influence on the estimates based on large numbers.  

``` {r frequency of user ratings, echo = FALSE}
# plot of the frequency of user ratings
edx %>%
  group_by(userId) %>%
  summarize(number = n()) %>% 
  ggplot(aes(number)) +
  geom_histogram(bins = 50, color = "black", fill = "#00abff") +
  scale_x_log10(labels = comma) +
  scale_y_continuous(labels = comma, breaks = pretty_breaks(n = 10)) +
  xlab("Frequency of Ratings (log scale)") +
  ylab("Frequency of Users") +
  theme_light() +
  ggtitle("Figure 4: Frequency of User Ratings (log scale)") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))
```
\

``` {r users with greatest number of ratings, echo = FALSE}
# users with the greatest number of ratings
edx %>% group_by(userId) %>% 
  summarise(number = n()) %>%
  arrange(desc(number)) %>%
  head(10) %>%
  kable(caption = "Users with the Most Ratings") %>%
  kable_styling(font_size = 10)
```
\
``` {r users with the least number of ratings, echo = FALSE}
# users with the fewest number of ratings
edx %>% group_by(userId) %>% 
  summarise(number = n()) %>%
  arrange(number) %>%
  head(10) %>%
  kable(caption = "Users with the Least Ratings") %>%
  kable_styling(font_size = 10)
```
\

Additionally, Figure 5 presents the average user rating (for users that have rated at least 100 movies). As seen in the graph, most users have an avergae rating between 3.00 and 4.25. Once again, it is evident that users differ substantially in how critical they are of the movies. Some users tend to provide much lower ratings compared to others. Thus, a user effect may be useful in the predictive models.

``` {r frequency of average rating, echo = FALSE}
# plot of the frequency of average user rating
edx %>%
  group_by(userId) %>%
  filter(n()>=100) %>%
  summarize(b_u = mean(rating)) %>% 
  ggplot(aes(b_u)) +
  geom_histogram(bins = 50, color = "Black", fill = "#00abff") +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  scale_y_continuous(labels = comma, breaks = pretty_breaks(n = 10)) +
  xlab("Average Rating") +
  ylab("Frequency of Users") +
  theme_light() +
  ggtitle("Figure 5: Frequency of Average User Rating") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))
```
\

## Time Effects  

The impact of time on movie ratings can be examined in a number of manners, including the age of the rating, the age of the movie, or the difference in time between the release of the movie and its rating. 

First, the plots in Figure 6 present the average rating across time, averaging across different time periods (i.e., weeks, months, and years). From these graphs, it is evident that the average rating varies slightly over time. The pattern is most apparent in the bottom graph with the date of rating rounded to the year. In this graph ,it can be seen that the average movie rated dropped from approximately 3.85 in 1995 to a low of approximately 3.45 in 2005 before rising again slightly to 3.55 in 2010. As such, the predictive models may benefit from the inclusion of term accounting for the date of the rating.  

``` {r average rating over time, echo = FALSE, message = FALSE, fig_height = 8}

# plot of average rating by week of rating
plot1<- edx_dates %>% mutate(week_rated = round_date(date_rated, unit = "week")) %>%
  group_by(week_rated) %>%
  summarize(average = mean(rating)) %>%
  ggplot(aes(x = week_rated, y = average)) +
  geom_point(alpha = 0.75) +
  geom_smooth(method = "loess") +
  scale_y_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Date of Rating Rounded to Week") +
  ylab("Average Rating") +
  theme_light() +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))

# plot of average rating by month of rating
plot2 <- edx_dates %>% mutate(month_rated = round_date(date_rated, unit = "month")) %>%
  group_by(month_rated) %>%
  summarize(average = mean(rating)) %>%
  ggplot(aes(x = month_rated, y = average)) +
  geom_point(alpha = 0.75) +
  geom_smooth(method = "loess") +
  scale_y_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Date of Rating Rounded to Month") +
  ylab("Average Rating") +
  theme_light() +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))

# plot of average rating by year of rating
plot3 <- edx_dates %>% mutate(year_rated = round_date(date_rated, unit = "year")) %>%
  group_by(year_rated) %>%
  summarize(average = mean(rating)) %>%
  ggplot(aes(x = year_rated, y = average)) +
  geom_point(alpha = 0.75) +
  geom_smooth(method = "loess") +
  scale_y_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Date of Rating Rounded to Year") +
  ylab("Average Rating") +
  theme_light() +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm"))

grid.arrange(plot1, plot2, plot3, top = "Figure 6: Average Rating Across Time")
```
\

However, as seen in Figure 7, the number of ratings per movie per year varies considerably. As such, the average rating per year of rating is basec don substantially different frequencies of ratings. The averages based on the larger numbers of observatnios are better estimates of the true means relative to those based on realtively few observations. As such, the predictive model may benefit from regularization in order to account for differences in the frequency of ratings per year.  

``` {r frequency of rating per year of rating, echo = FALSE}
# plot of frequency of ratings by year of rating
edx_dates %>%
  group_by(movieId) %>%
  summarize(number = n(), year = as.character(first(year_rated))) %>% 
  ggplot(aes(x = year, y = number)) +
  geom_boxplot(color = "black", fill = "#00abff") +
  scale_y_sqrt(labels = comma, breaks = pretty_breaks(n = 10)) +
  scale_x_discrete(breaks = pretty_breaks(n = 10)) +
  xlab("Year of Rating") +
  ylab("Frequency of Ratings for Each Movie") +
  theme_light() +
  ggtitle("Figure 7: Frequency of Ratings per Movie by Year of Rating") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
\

Next, the year of release was examined. Figure 8 presents the frequency of ratings by year of movie release, while Figure 9 presents the average rating by year of release. Based on Figure 8, it can be seen that the frequency of ratings varies considerably based on the release year of the movie. Movies released in the 1980s and 1990s have received the most ratings, while older movies tend to receive fewer and fewer ratings (with the exception of some movies released in the 1940s). 

Although movies in the 1980s and 1990s received the greatest number of ratings and older movies received relatively few ratings, the average movie rating presented in Figure 9 shows a different pattern. The average movie appears to depict a non-linear relationship that rises from the 1920s peaking in the 1940s before falling bakc down beginning in the 1960s.  

``` {r frequency of ratings by release date, echo = FALSE}
# plot of frequency of ratings by date of release
edx_dates %>%
  group_by(movieId) %>%
  summarize(number = n(), year = as.character(first(year_released))) %>% 
  ggplot(aes(x = year, y = number)) +
  geom_boxplot(color = "black", fill = "#00abff") +
  scale_y_sqrt(labels = comma, breaks = pretty_breaks(n = 10)) +
  scale_x_discrete(breaks = pretty_breaks(n = 10)) +
  xlab("Release Year") +
  ylab("Frequency of Ratings") +
  theme_light() +
  ggtitle("Figure 8: Frequency of Ratings by Release Year") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
\

``` {r average rating by release date, echo = FALSE, message = FALSE}
# plot of average ratings by date of release
edx_dates %>%
  group_by(year_released) %>%
  summarize(average = mean(rating)) %>% 
  ggplot(aes(x = year_released, y = average)) +
  geom_point(alpha = 0.75) +
  geom_smooth(method = "loess") +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  scale_y_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Release Year") +
  ylab("Average Rating") +
  theme_light() +
  ggtitle("Figure 9: Average Rating by Release Year") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Additionally, the impact of the time was examined in Figure 10. This figure presents the average movie rating by the number of ratings per year. Generally, as the number of ratings per year increases, so does the average rating. That is, movies with the fewwest ratings per year tend to have an avergae rating just over 3.0, while the movies with the most ratings per year tend to have an average rating over 4.0. The differenec in average rating between the movies with the most ratings per year compared to the movies with the least ratings per year can be seen in Tables 8 and 9. These tables present the movies with the most and least ratings per year, respectively. 

``` {r average rating by ratings per year , echo = FALSE}
# plot of average rating by rating per year 
edx_dates %>%
  group_by(movieId) %>%
  summarize(n = n(), years = 2010 - first(year_released),
            title = title[1],
            rating = mean(rating)) %>%
  mutate(rate = n/years) %>%
  ggplot(aes(x = rate, y = rating)) +
  geom_point(alpha = 0.75) +
  geom_smooth(method = "loess") +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  scale_y_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Ratings per Year") +
  ylab("Average Rating") +
  theme_light() +
  ggtitle("Figure 10: Average Rating by Ratings per Year") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
\

``` {r table of most rated movies per year, echo = FALSE}
# table of top movies by ratings per year 
edx_dates %>% 
  group_by(movieId) %>%
  summarize(n = n(), years = 2010 - first(year_released),
            title = title[1],
            rating = mean(rating)) %>%
  mutate(rate = n/years) %>%
  top_n(10, rate) %>%
  arrange(desc(rate)) %>%
  kable(caption = "Movies with the Most ratings per Year") %>%
  kable_styling(font_size = 10)
```
\

``` {r table of least rated movies per year, echo = FALSE}
# table of least movies by ratings per year 
edx_dates %>% 
  group_by(movieId) %>%
  summarize(n = n(), years = 2010 - first(year_released),
            title = title[1],
            rating = mean(rating)) %>%
  mutate(rate = n/years) %>%
  top_n(-10, rate) %>%
  arrange(rate) %>%
  kable(caption = "Movies with the Least Ratings per Year") %>%
  kable_styling(font_size = 10)
```
\

Finally, the impact of time on ratings was investigated by examinging the relative age of the ratings (i.e., the number of years in between the date of the rating and the date of release, calculated by substracting the year of release from the year of the rating). Figure 11 presents the frequency of ratings per movie by the average relative age of the rating, while Figure 12 presents the average rating by average relative age of rating. As seen in these graphs, most ratings were provided relatively closely to the release of the movie (i.e., with an average relative age of rating less than 20 years). As well, it appears there is a relationship between the average rating and the relative age of the ratings. Generally, relatively older ratings (i.e., ratings provided longer after the movie release) have a slightly hi9gher mean than relatively younger ratings. 

``` {r frequency of rating by average relative age of rating, echo = FALSE}
# plot of frequency of ratings by relative age of rating
edx_dates %>%
  group_by(movieId) %>% 
  summarize(number = n(), average_year = mean(relative_rating_age)) %>% 
  ggplot(aes(x = average_year, y = number)) +
  geom_point(stat = "identity", color = "black", fill = "#00abff") +
  scale_y_sqrt(labels = comma, breaks = pretty_breaks(n = 10)) +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Average Relative Age of Rating") +
  ylab("Frequency of Ratings") +
  theme_light() +
  ggtitle("Figure 11: Frequency of Ratings by Average Relative Age of Rating") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
\

``` {r average rating by average relative age of rating, echo = FALSE}
# plot of average of ratings by relative age of rating
edx_dates %>%
  group_by(movieId) %>%
  summarize(average = mean(rating), average_year = mean(relative_rating_age)) %>% 
  ggplot(aes(x = average_year, y = average)) +
  geom_point(color = "black", fill = "#00abff") +
  geom_smooth(method = "loess") +
  scale_y_continuous(labels = comma, breaks = pretty_breaks(n = 10)) +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Average Relative Age of Rating") +
  ylab("Average Rating") +
  theme_light() +
  ggtitle("Figure 12: Average Rating by Average Relative Age of Rating") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
\

## Genre Effects  

As described above, the genre information consists of a pipe separated string variable that references all of the relevant genres for a given movie. Thus, some movies receive only a single genre tag while others receive multiple genre tags. This can be seen in Table 10, which presents the number and avergae ratings for the ten most common genre combinations. In contrast, Table 11 presents the number and average ratings for each of the ten most common individual genre tags. As such, due to the manner in which the genre infromation is stored, two possibilities present themselves: treat the overall genre combinations as separate factors, or treat each individual genre tag as a separate factor. Each of these approaches were undertaken.  

``` {r table of ratings by overall genre combinations, echo = FALSE}
# table of number of ratings and average rating by overall genre combination
edx %>% group_by(genres) %>%
  summarize(number = n(), average = mean(rating)) %>%
  arrange(desc(number)) %>%
  slice(1:10) %>%
  kable(caption = "Number and Average Rating by Overall Genre Combination") %>%
  kable_styling(font_size = 10)
```
\

``` {r table of ratings by individual genre tags, echo = FALSE}
# table of number of ratings and average rating by separate movie genres (CAUTION slow code)
edx %>% separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarize(number = n(), average = mean(rating)) %>%
  arrange(desc(number)) %>%
  kable(caption = "Number and Average Rating by Individual Genre Tags") %>%
  kable_styling(font_size = 10)
```
\

First, the overall genre combinations were examined (i.e., treating each specific combination of genre tags as a separate factor). Considered in this manner, there are 797 unique genre combinations. 

Figure 13 presents the frequency of ratings for all of the genre combinations with at least 1000 ratings in descending order. As seen in this figure and Table 10, two genre combinations have received nearly twice as many ratings as all of the other combinations (i.e., "Drama" and "Comedy") and the top six categories have received the majority of ratings and are all closely related genre combinations. As well, Figure 14 presents the average rating for all of the genre combinations with at least 1000 ratings in descending order, with error bars around the means set to plus or minus two standard errors. The average rating for some genre combinations peaks at a high of just over 4.3 compared to the lowest values of under 2.1. Therefore, it seems that overall genre combination may be a useful variable to include in the predictive models. 

``` {r frequency of ratings by overall genre combination, echo = FALSE}
# plot of the number of rating by overall genre combination (for genres with n >= 1000)
edx %>% group_by(genres) %>%
  summarise(number = n()) %>%
  filter(number >= 1000) %>% 
  mutate(genres = reorder(genres, -number)) %>%
  ggplot(aes(x = genres, y = number)) + 
  geom_bar(stat = "identity", color = "#00abff") +
  scale_y_sqrt(labels = comma, breaks = pretty_breaks(n = 10)) +
  xlab("Overall Genre Combinations") +
  ylab("Frequency of Ratings") +
  theme_light() +
  ggtitle("Figure 13: Frequency of Ratings by Overall Genre Combination") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_blank())
```
\

``` {r average rating by overall genre combination, echo = FALSE}
# plot of average rating by overall genre combination (for genres with n >= 1000)
edx %>% group_by(genres) %>%
  summarize(number = n(), average = mean(rating), se = sd(rating)/sqrt(n())) %>%
  filter(number >= 1000) %>% 
  mutate(genres = reorder(genres, -average)) %>%
  ggplot(aes(x = genres, y = average, ymin = average - 2*se, ymax = average + 2*se)) + 
  geom_point(color = "#00abff") +
  geom_errorbar(color = "Black") + 
  scale_y_continuous(breaks = pretty_breaks(n = 10)) +
  xlab("Overall Genre Combinations") +
  ylab("Average Rating") +
  theme_light() +
  ggtitle("Figure 14: Average Rating by Overall Genre Combination") +
  theme(axis.title.x = element_text(vjust = -3)) +
  theme(axis.title.y = element_text(angle = 90, vjust = 3)) +
  theme(plot.title = element_text(size = 15, vjust = 5, hjust = 0.5)) +
  theme(plot.margin = unit(c(1,1,1,1), "cm")) +
  theme(axis.text.x = element_blank())
```
\

# Modeling Approaches  

## Movie Effects  

## User Effects  

## Regularized Movie and User Effects  

## Time Effects  

## Genre Effects  

# Results on Validation Set  

# Discussion  

## Limitations  

## Future Directions  

``` {r template, echo = FALSE}
# code

```


# Appendix  

```{r print environment, echo = FALSE}
print("Operating System and R Version Information")
version
```
